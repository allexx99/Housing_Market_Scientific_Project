{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-12-07T22:15:14.740580Z",
     "start_time": "2024-12-07T22:15:14.735922Z"
    }
   },
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.stats import zscore\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "np.random.seed(0)"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T22:15:44.000877Z",
     "start_time": "2024-12-07T22:15:14.780201Z"
    }
   },
   "cell_type": "code",
   "source": [
    "file_path = 'modified_dataset/us_project_outliers.csv'\n",
    "\n",
    "us_ds = pd.read_csv(file_path, sep=',')"
   ],
   "id": "5609e29f7426da49",
   "outputs": [],
   "execution_count": 2
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T22:15:44.949617Z",
     "start_time": "2024-12-07T22:15:44.726911Z"
    }
   },
   "cell_type": "code",
   "source": [
    "us_ds['sin_year'] = np.sin(2 * np.pi * us_ds['year'] / 12)\n",
    "us_ds['cos_year'] = np.cos(2 * np.pi * us_ds['year'] / 12)\n",
    "\n",
    "us_ds['sin_month'] = np.sin(2 * np.pi * us_ds['month'] / 12)\n",
    "us_ds['cos_month'] = np.cos(2 * np.pi * us_ds['month'] / 12)"
   ],
   "id": "ec2bd3600ed1061b",
   "outputs": [],
   "execution_count": 3
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T22:15:45.568073Z",
     "start_time": "2024-12-07T22:15:45.532450Z"
    }
   },
   "cell_type": "code",
   "source": "us_ds.head(100)",
   "id": "4017da1c8c28c319",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "   period_begin  period_end  period_duration region_type  region_type_id  \\\n",
       "0    2017-09-01  2017-09-30               30       place               6   \n",
       "1    2020-07-01  2020-07-31               30       place               6   \n",
       "2    2021-08-01  2021-08-31               30       place               6   \n",
       "3    2018-08-01  2018-08-31               30       place               6   \n",
       "4    2023-01-01  2023-01-31               30       place               6   \n",
       "..          ...         ...              ...         ...             ...   \n",
       "95   2024-07-01  2024-07-31               30       place               6   \n",
       "96   2020-01-01  2020-01-31               30       place               6   \n",
       "97   2013-09-01  2013-09-30               30       place               6   \n",
       "98   2024-06-01  2024-06-30               30       place               6   \n",
       "99   2020-07-01  2020-07-31               30       place               6   \n",
       "\n",
       "    table_id is_seasonally_adjusted                      region  \\\n",
       "0      29470                      f                 Chicago, IL   \n",
       "1      37598                      f              Parsippany, NJ   \n",
       "2      24993                      f                Oakbrook, KY   \n",
       "3      29754                      f               Dunstable, MA   \n",
       "4      10728                      f               Kalamazoo, MI   \n",
       "..       ...                    ...                         ...   \n",
       "95     16583                      f                    Saco, ME   \n",
       "96     10233                      f               Lancaster, CA   \n",
       "97     24533                      f  Ocean Bluff-Brant Rock, MA   \n",
       "98     15188                      f                   Ogden, IA   \n",
       "99     11598                      f           Lawrenceville, GA   \n",
       "\n",
       "                      city          state  ... price_increased_mom  \\\n",
       "0                  Chicago       Illinois  ...                   1   \n",
       "1               Parsippany     New Jersey  ...                   0   \n",
       "2                 Oakbrook       Kentucky  ...                   0   \n",
       "3                Dunstable  Massachusetts  ...                   1   \n",
       "4                Kalamazoo       Michigan  ...                   1   \n",
       "..                     ...            ...  ...                 ...   \n",
       "95                    Saco          Maine  ...                   0   \n",
       "96               Lancaster     California  ...                   0   \n",
       "97  Ocean Bluff-Brant Rock  Massachusetts  ...                   0   \n",
       "98                   Ogden           Iowa  ...                   0   \n",
       "99           Lawrenceville        Georgia  ...                   1   \n",
       "\n",
       "   price_increased_yoy  inventory_turnover  sale_to_list_ppsf_ratio  \\\n",
       "0                    1            0.215805                 0.517397   \n",
       "1                    0            0.700000                 0.975611   \n",
       "2                    1            1.700000                 0.925068   \n",
       "3                    0            0.400000                 1.158641   \n",
       "4                    1            0.415842                 0.996442   \n",
       "..                 ...                 ...                      ...   \n",
       "95                   0            0.500000                 1.153662   \n",
       "96                   1            0.496795                 1.003815   \n",
       "97                   0            0.146341                 0.866614   \n",
       "98                   1            0.857143                 1.678848   \n",
       "99                   1            0.243243                 1.159940   \n",
       "\n",
       "    supply_demand_balance  fast_selling  sin_year      cos_year     sin_month  \\\n",
       "0                    55.0             0  0.500000  8.660254e-01 -1.000000e+00   \n",
       "1                     3.0             0  0.866025 -5.000000e-01 -5.000000e-01   \n",
       "2                     3.0             1  0.500000 -8.660254e-01 -8.660254e-01   \n",
       "3                     0.0             0  0.866025  5.000000e-01 -8.660254e-01   \n",
       "4                    -8.0             1 -0.500000 -8.660254e-01  5.000000e-01   \n",
       "..                    ...           ...       ...           ...           ...   \n",
       "95                   -2.0             1 -0.866025 -5.000000e-01 -5.000000e-01   \n",
       "96                  -37.0             0  0.866025 -5.000000e-01  5.000000e-01   \n",
       "97                   -3.0             0 -1.000000  7.792901e-14 -1.000000e+00   \n",
       "98                   -2.0             0 -0.866025 -5.000000e-01  1.224647e-16   \n",
       "99                    4.0             0  0.866025 -5.000000e-01 -5.000000e-01   \n",
       "\n",
       "       cos_month  \n",
       "0  -1.836970e-16  \n",
       "1  -8.660254e-01  \n",
       "2  -5.000000e-01  \n",
       "3  -5.000000e-01  \n",
       "4   8.660254e-01  \n",
       "..           ...  \n",
       "95 -8.660254e-01  \n",
       "96  8.660254e-01  \n",
       "97 -1.836970e-16  \n",
       "98 -1.000000e+00  \n",
       "99 -8.660254e-01  \n",
       "\n",
       "[100 rows x 72 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>period_begin</th>\n",
       "      <th>period_end</th>\n",
       "      <th>period_duration</th>\n",
       "      <th>region_type</th>\n",
       "      <th>region_type_id</th>\n",
       "      <th>table_id</th>\n",
       "      <th>is_seasonally_adjusted</th>\n",
       "      <th>region</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>...</th>\n",
       "      <th>price_increased_mom</th>\n",
       "      <th>price_increased_yoy</th>\n",
       "      <th>inventory_turnover</th>\n",
       "      <th>sale_to_list_ppsf_ratio</th>\n",
       "      <th>supply_demand_balance</th>\n",
       "      <th>fast_selling</th>\n",
       "      <th>sin_year</th>\n",
       "      <th>cos_year</th>\n",
       "      <th>sin_month</th>\n",
       "      <th>cos_month</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2017-09-01</td>\n",
       "      <td>2017-09-30</td>\n",
       "      <td>30</td>\n",
       "      <td>place</td>\n",
       "      <td>6</td>\n",
       "      <td>29470</td>\n",
       "      <td>f</td>\n",
       "      <td>Chicago, IL</td>\n",
       "      <td>Chicago</td>\n",
       "      <td>Illinois</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.215805</td>\n",
       "      <td>0.517397</td>\n",
       "      <td>55.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>8.660254e-01</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>-1.836970e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>2020-07-31</td>\n",
       "      <td>30</td>\n",
       "      <td>place</td>\n",
       "      <td>6</td>\n",
       "      <td>37598</td>\n",
       "      <td>f</td>\n",
       "      <td>Parsippany, NJ</td>\n",
       "      <td>Parsippany</td>\n",
       "      <td>New Jersey</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.975611</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>-5.000000e-01</td>\n",
       "      <td>-5.000000e-01</td>\n",
       "      <td>-8.660254e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2021-08-01</td>\n",
       "      <td>2021-08-31</td>\n",
       "      <td>30</td>\n",
       "      <td>place</td>\n",
       "      <td>6</td>\n",
       "      <td>24993</td>\n",
       "      <td>f</td>\n",
       "      <td>Oakbrook, KY</td>\n",
       "      <td>Oakbrook</td>\n",
       "      <td>Kentucky</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1.700000</td>\n",
       "      <td>0.925068</td>\n",
       "      <td>3.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-8.660254e-01</td>\n",
       "      <td>-8.660254e-01</td>\n",
       "      <td>-5.000000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018-08-01</td>\n",
       "      <td>2018-08-31</td>\n",
       "      <td>30</td>\n",
       "      <td>place</td>\n",
       "      <td>6</td>\n",
       "      <td>29754</td>\n",
       "      <td>f</td>\n",
       "      <td>Dunstable, MA</td>\n",
       "      <td>Dunstable</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>1.158641</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>-8.660254e-01</td>\n",
       "      <td>-5.000000e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2023-01-01</td>\n",
       "      <td>2023-01-31</td>\n",
       "      <td>30</td>\n",
       "      <td>place</td>\n",
       "      <td>6</td>\n",
       "      <td>10728</td>\n",
       "      <td>f</td>\n",
       "      <td>Kalamazoo, MI</td>\n",
       "      <td>Kalamazoo</td>\n",
       "      <td>Michigan</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.415842</td>\n",
       "      <td>0.996442</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-8.660254e-01</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>8.660254e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>2024-07-01</td>\n",
       "      <td>2024-07-31</td>\n",
       "      <td>30</td>\n",
       "      <td>place</td>\n",
       "      <td>6</td>\n",
       "      <td>16583</td>\n",
       "      <td>f</td>\n",
       "      <td>Saco, ME</td>\n",
       "      <td>Saco</td>\n",
       "      <td>Maine</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>1.153662</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>-5.000000e-01</td>\n",
       "      <td>-5.000000e-01</td>\n",
       "      <td>-8.660254e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>2020-01-01</td>\n",
       "      <td>2020-01-31</td>\n",
       "      <td>30</td>\n",
       "      <td>place</td>\n",
       "      <td>6</td>\n",
       "      <td>10233</td>\n",
       "      <td>f</td>\n",
       "      <td>Lancaster, CA</td>\n",
       "      <td>Lancaster</td>\n",
       "      <td>California</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.496795</td>\n",
       "      <td>1.003815</td>\n",
       "      <td>-37.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>-5.000000e-01</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>8.660254e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>2013-09-01</td>\n",
       "      <td>2013-09-30</td>\n",
       "      <td>30</td>\n",
       "      <td>place</td>\n",
       "      <td>6</td>\n",
       "      <td>24533</td>\n",
       "      <td>f</td>\n",
       "      <td>Ocean Bluff-Brant Rock, MA</td>\n",
       "      <td>Ocean Bluff-Brant Rock</td>\n",
       "      <td>Massachusetts</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.146341</td>\n",
       "      <td>0.866614</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.000000</td>\n",
       "      <td>7.792901e-14</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>-1.836970e-16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>2024-06-01</td>\n",
       "      <td>2024-06-30</td>\n",
       "      <td>30</td>\n",
       "      <td>place</td>\n",
       "      <td>6</td>\n",
       "      <td>15188</td>\n",
       "      <td>f</td>\n",
       "      <td>Ogden, IA</td>\n",
       "      <td>Ogden</td>\n",
       "      <td>Iowa</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.857143</td>\n",
       "      <td>1.678848</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>-5.000000e-01</td>\n",
       "      <td>1.224647e-16</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>2020-07-01</td>\n",
       "      <td>2020-07-31</td>\n",
       "      <td>30</td>\n",
       "      <td>place</td>\n",
       "      <td>6</td>\n",
       "      <td>11598</td>\n",
       "      <td>f</td>\n",
       "      <td>Lawrenceville, GA</td>\n",
       "      <td>Lawrenceville</td>\n",
       "      <td>Georgia</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.243243</td>\n",
       "      <td>1.159940</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>-5.000000e-01</td>\n",
       "      <td>-5.000000e-01</td>\n",
       "      <td>-8.660254e-01</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 72 columns</p>\n",
       "</div>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 4
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T22:15:46.123427Z",
     "start_time": "2024-12-07T22:15:46.096320Z"
    }
   },
   "cell_type": "code",
   "source": [
    "def add_intercept(us_ds):\n",
    "    print(\"In add_intercept function...\")\n",
    "    us_ds_with_bias = np.c_[np.ones(us_ds.shape[0]), us_ds]\n",
    "    return us_ds_with_bias\n",
    "\n",
    "def normalize(us_ds, mean=None, std=None):\n",
    "    print(\"In normalize function...\")\n",
    "    us_ds_normalized = us_ds.copy()\n",
    "    \n",
    "    # Normalize only the selected numeric columns\n",
    "    us_ds_normalized = (us_ds_normalized - mean) / std\n",
    "    \n",
    "    # us_ds_normalized = (us_ds - mean) / std\n",
    "    return us_ds_normalized\n",
    "\n",
    "def split_data(us_ds, state_column, ratio=0.8):\n",
    "    train_data = []\n",
    "    test_data = []\n",
    "    \n",
    "    # grouped by the state column\n",
    "    grouped = us_ds.groupby(state_column)\n",
    "    \n",
    "    for state, group in grouped:\n",
    "        num_samples = len(group)\n",
    "        n_train = int(num_samples * ratio)\n",
    "        \n",
    "        # shuffle indices for randomization\n",
    "        indices = np.random.permutation(num_samples)\n",
    "        \n",
    "        train_indices = indices[:n_train]\n",
    "        test_indices = indices[n_train:]\n",
    "        \n",
    "        # split into train and test for this state\n",
    "        train_group = group.iloc[train_indices]\n",
    "        test_group = group.iloc[test_indices]\n",
    "        \n",
    "        # append to overall train and test sets\n",
    "        train_data.append(train_group)\n",
    "        test_data.append(test_group)\n",
    "    \n",
    "    print(\"In split function...\")\n",
    "    # print(train_data[0]['state_code'])\n",
    "    print(f\"train_data len: {len(train_data)}\")\n",
    "    print(f\"test_data len: {len(test_data)}\")\n",
    "    print(\"Train shape\")\n",
    "    print(train_data[0].shape)\n",
    "    print(\"Test shape\")\n",
    "    print(test_data[0].shape)\n",
    "    \n",
    "    # concatenate all groups to form the final train and test datasets\n",
    "    print(\"Start concatenation of train data frames...\")\n",
    "    train_data = pd.concat(train_data).reset_index(drop=True)\n",
    "    print(\"Start concatenation of test data frames...\")\n",
    "    test_data = pd.concat(test_data).reset_index(drop=True)\n",
    "    \n",
    "    return train_data, test_data\n",
    "\n",
    "# def split_data_ca(us_ds, ratio=0.8):\n",
    "#     us_ds_ca = us_ds[us_ds['state_code'] == 'CA']\n",
    "#     \n",
    "#     num_samples = us_ds_ca.shape[0]\n",
    "#     n_train = int(num_samples * ratio)\n",
    "#     indices = np.random.permutation(num_samples)\n",
    "#     \n",
    "#     train_indices = indices[:n_train]\n",
    "#     test_indices = indices[n_train:]\n",
    "#     \n",
    "#     us_ds_ca_train = us_ds_ca.iloc[train_indices]\n",
    "#     us_ds_ca_test = us_ds_ca.iloc[test_indices]\n",
    "#     \n",
    "#     return us_ds_ca_train, us_ds_ca_test\n",
    "\n",
    "def preprocess_data(us_ds, state_column, ratio=0.8):\n",
    "    us_ds_train, us_ds_test = None, None\n",
    "    \n",
    "    # split the data\n",
    "    print(\"Start splitting...\")\n",
    "    us_ds_train, us_ds_test = split_data(us_ds, state_column, ratio)\n",
    "    \n",
    "    print(\"In process_data function...\")\n",
    "    print(\"Train shape\")\n",
    "    print(us_ds_train.shape)\n",
    "    print(\"Test shape\")\n",
    "    print(us_ds_test.shape)\n",
    "    \n",
    "    exclude_columns = ['period_duration', 'region_type_id', 'table_id', 'property_type_id', 'parent_metro_region_metro_code', 'year', 'month', 'price_increased_mom', 'price_increased_yoy', 'fast_selling']\n",
    "    \n",
    "    # compute the mean and std of the training data\n",
    "    print(\"Start computing mean and std...\")\n",
    "    numeric_columns = us_ds_train.select_dtypes(include=['number']).columns\n",
    "\n",
    "    if exclude_columns:\n",
    "        columns_for_mean_std = [col for col in numeric_columns if col not in exclude_columns]\n",
    "    else:\n",
    "        columns_for_mean_std = numeric_columns\n",
    "    \n",
    "    mean = np.mean(us_ds_train[columns_for_mean_std], axis=0)\n",
    "    std = np.std(us_ds_train[columns_for_mean_std], axis=0)\n",
    "    \n",
    "    print(\"Preprocessing the entire data set...\")\n",
    "    us_ds_final = preprocess_entire_dataset(us_ds, mean, std)\n",
    "    \n",
    "    print(\"Continuing with the split data...\")\n",
    "    # normalize the data\n",
    "    print(\"Start normalizing...\")\n",
    "    # Normalize the training data\n",
    "    \n",
    "    us_ds_train_normalized = us_ds_train.copy()\n",
    "    us_ds_test_normalized = us_ds_test.copy()\n",
    "    \n",
    "    us_ds_train_normalized[columns_for_mean_std] = normalize(us_ds_train[columns_for_mean_std], mean, std)\n",
    "    us_ds_test_normalized[columns_for_mean_std] = normalize(us_ds_test[columns_for_mean_std], mean, std)\n",
    "     \n",
    "    # add intercept to both training and testing data\n",
    "    print(\"Start adding intercept...\")\n",
    "    train_intercept = add_intercept(us_ds_train_normalized)\n",
    "    test_intercept = add_intercept(us_ds_test_normalized)\n",
    "     \n",
    "    print(\"Finishing...\")\n",
    "    us_ds_train = train_intercept\n",
    "    us_ds_test = test_intercept\n",
    "    \n",
    "    return us_ds_train, us_ds_test, us_ds_final\n",
    "\n",
    "def preprocess_entire_dataset(us_ds, mean, std):\n",
    "    exclude_columns = ['period_duration', 'region_type_id', 'table_id', 'property_type_id',\n",
    "    'parent_metro_region_metro_code', 'year', 'month', 'price_increased_mom',\n",
    "    'price_increased_yoy', 'fast_selling']\n",
    "    \n",
    "    numeric_columns = us_ds.select_dtypes(include=['number']).columns\n",
    "    \n",
    "    if exclude_columns:\n",
    "        columns_to_normalize = [col for col in numeric_columns if col not in exclude_columns]\n",
    "    else:\n",
    "        columns_to_normalize = numeric_columns\n",
    "    \n",
    "    # normalize\n",
    "    print(\"Start normalizing...\")\n",
    "    print(\"In preprocess entire...\")\n",
    "    us_ds_normalized = us_ds.copy()\n",
    "    us_ds_normalized[columns_to_normalize] = normalize(us_ds[columns_to_normalize], mean, std)\n",
    "    \n",
    "    # add intercept\n",
    "    print(\"Start adding intercept...\")\n",
    "    us_ds_intercept = add_intercept(us_ds_normalized)\n",
    "    \n",
    "    # finishing\n",
    "    print(\"Finishing...\")\n",
    "    us_ds_final = us_ds_intercept\n",
    "    \n",
    "    return us_ds_final"
   ],
   "id": "6ad16ef5e614f294",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T22:18:27.616297Z",
     "start_time": "2024-12-07T22:15:46.222100Z"
    }
   },
   "cell_type": "code",
   "source": [
    "state_column = 'state_code'\n",
    "us_ds_train, us_ds_test, us_ds_final = preprocess_data(us_ds, state_column)\n",
    "\n",
    "print(\"The shape of the training set is:\")\n",
    "print(us_ds_train.shape)\n",
    "print(\"The shape of the test set is:\")\n",
    "print(us_ds_test.shape)"
   ],
   "id": "d18a530c15b1d308",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start splitting...\n",
      "In split function...\n",
      "train_data len: 48\n",
      "test_data len: 48\n",
      "Train shape\n",
      "(942, 72)\n",
      "Test shape\n",
      "(236, 72)\n",
      "Start concatenation of train data frames...\n",
      "Start concatenation of test data frames...\n",
      "In process_data function...\n",
      "Train shape\n",
      "(1431347, 72)\n",
      "Test shape\n",
      "(357865, 72)\n",
      "Start computing mean and std...\n",
      "Preprocessing the entire data set...\n",
      "Start normalizing...\n",
      "In preprocess entire...\n",
      "In normalize function...\n",
      "Start adding intercept...\n",
      "In add_intercept function...\n",
      "Finishing...\n",
      "Continuing with the split data...\n",
      "Start normalizing...\n",
      "In normalize function...\n",
      "In normalize function...\n",
      "Start adding intercept...\n",
      "In add_intercept function...\n",
      "In add_intercept function...\n",
      "Finishing...\n",
      "The shape of the training set is:\n",
      "(1431347, 73)\n",
      "The shape of the test set is:\n",
      "(357865, 73)\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T22:20:35.536377Z",
     "start_time": "2024-12-07T22:18:30.682970Z"
    }
   },
   "cell_type": "code",
   "source": [
    "output_file = 'modified_dataset/us_project_normalize_train.csv'\n",
    "\n",
    "column_names = ['intercept'] + list(us_ds.columns)\n",
    "us_ds_train = pd.DataFrame(us_ds_train, columns=column_names)\n",
    "\n",
    "us_ds_train.to_csv(output_file, index=False)"
   ],
   "id": "aadf20c6258fe646",
   "outputs": [],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T22:21:10.047761Z",
     "start_time": "2024-12-07T22:20:38.756597Z"
    }
   },
   "cell_type": "code",
   "source": [
    "output_file = 'modified_dataset/us_project_normalize_test.csv'\n",
    "\n",
    "us_ds_test = pd.DataFrame(us_ds_test, columns=column_names)\n",
    "\n",
    "us_ds_test.to_csv(output_file, index=False)"
   ],
   "id": "d724594125a9952",
   "outputs": [],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T22:21:11.139812Z",
     "start_time": "2024-12-07T22:21:11.133833Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# def group_by_state(us_ds, state_column):\n",
    "#     # grouped by the state column\n",
    "#     grouped = us_ds.groupby(state_column)\n",
    "#     print(\"What states are in the dataset\")\n",
    "#     cnt = 0\n",
    "#     for state, group in grouped:\n",
    "#         print(f\"{state}: {len(group)}\")\n",
    "#         cnt+=1\n",
    "#     print(\"Total number of states:\", cnt)"
   ],
   "id": "4e7e3afa6fb5815c",
   "outputs": [],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T22:21:12.206750Z",
     "start_time": "2024-12-07T22:21:12.169444Z"
    }
   },
   "cell_type": "code",
   "source": "us_ds_final.shape",
   "id": "9c470b8d641aeed6",
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1789212, 73)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T22:24:03.086945Z",
     "start_time": "2024-12-07T22:21:13.252995Z"
    }
   },
   "cell_type": "code",
   "source": [
    "output_file = 'modified_dataset/us_project_normalize.csv'\n",
    "\n",
    "column_names = ['intercept'] + list(us_ds.columns)\n",
    "us_ds_final = pd.DataFrame(us_ds_final, columns=column_names)\n",
    "\n",
    "us_ds_final.to_csv(output_file, index=False)"
   ],
   "id": "358ae2d5a226b469",
   "outputs": [],
   "execution_count": 11
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-07T22:24:12.347157Z",
     "start_time": "2024-12-07T22:24:12.342837Z"
    }
   },
   "cell_type": "code",
   "source": "",
   "id": "5102bba1dd676a86",
   "outputs": [],
   "execution_count": null
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
